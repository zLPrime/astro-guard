{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BBVpWoUipweW"
      },
      "outputs": [],
      "source": [
        "%load_ext cudf.pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZteNlRGuoDv",
        "outputId": "feb07417-b706-4e4e-ebc0-344888fbc9e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting awscli\n",
            "  Downloading awscli-1.38.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.37.13 (from awscli)\n",
            "  Downloading botocore-1.37.13-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting docutils<0.17,>=0.10 (from awscli)\n",
            "  Downloading docutils-0.16-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from awscli)\n",
            "  Downloading s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: PyYAML<6.1,>=3.10 in /usr/local/lib/python3.11/dist-packages (from awscli) (6.0.2)\n",
            "Collecting colorama<0.4.7,>=0.2.5 (from awscli)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting rsa<4.8,>=3.1.2 (from awscli)\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from botocore==1.37.13->awscli)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore==1.37.13->awscli) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore==1.37.13->awscli) (2.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.37.13->awscli) (1.17.0)\n",
            "Downloading awscli-1.38.13-py3-none-any.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.37.13-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Downloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: rsa, jmespath, docutils, colorama, botocore, s3transfer, awscli\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.21.2\n",
            "    Uninstalling docutils-0.21.2:\n",
            "      Successfully uninstalled docutils-0.21.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sphinx 8.1.3 requires docutils<0.22,>=0.20, but you have docutils 0.16 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed awscli-1.38.13 botocore-1.37.13 colorama-0.4.6 docutils-0.16 jmespath-1.0.1 rsa-4.7.2 s3transfer-0.11.4\n"
          ]
        }
      ],
      "source": [
        "! pip install awscli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FITHOzi3vHQF",
        "outputId": "68a5a0ef-b48d-4a5f-c0d3-2adb0c3c5302"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.37.13-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: botocore<1.38.0,>=1.37.13 in /usr/local/lib/python3.11/dist-packages (from boto3) (1.37.13)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3) (0.11.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.13->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.13->boto3) (2.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.13->boto3) (1.17.0)\n",
            "Downloading boto3-1.37.13-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.6/139.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: boto3\n",
            "Successfully installed boto3-1.37.13\n"
          ]
        }
      ],
      "source": [
        "! pip install boto3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDjMazXi4Pse",
        "outputId": "d01c9ce0-95ee-4276-dbba-af3baf991dfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting skypatrol\n",
            "  Downloading skypatrol-0.6.16-py3-none-any.whl.metadata (408 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from skypatrol) (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from skypatrol) (2.2.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from skypatrol) (18.1.0)\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.11/dist-packages (from skypatrol) (7.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from skypatrol) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from skypatrol) (3.10.0)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from skypatrol) (4.67.1)\n",
            "Requirement already satisfied: pyerfa>=2.0.1.1 in /usr/local/lib/python3.11/dist-packages (from astropy->skypatrol) (2.0.1.5)\n",
            "Requirement already satisfied: astropy-iers-data>=0.2025.1.31.12.41.4 in /usr/local/lib/python3.11/dist-packages (from astropy->skypatrol) (0.2025.3.10.0.29.26)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from astropy->skypatrol) (6.0.2)\n",
            "Requirement already satisfied: packaging>=22.0.0 in /usr/local/lib/python3.11/dist-packages (from astropy->skypatrol) (24.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->skypatrol) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->skypatrol) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->skypatrol) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->skypatrol) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->skypatrol) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->skypatrol) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->skypatrol) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->skypatrol) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->skypatrol) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->skypatrol) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->skypatrol) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->skypatrol) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->skypatrol) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->skypatrol) (1.17.0)\n",
            "Downloading skypatrol-0.6.16-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: skypatrol\n",
            "Successfully installed skypatrol-0.6.16\n"
          ]
        }
      ],
      "source": [
        "!pip3 install skypatrol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGX49oyAwBjn",
        "outputId": "3d56efa9-c03a-4024-9870-458016f749a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/isadoranun/FATS@aa81ce7f68d137798126b6e425dd069c3b4fde3a\n",
            "  Cloning https://github.com/isadoranun/FATS (to revision aa81ce7f68d137798126b6e425dd069c3b4fde3a) to /tmp/pip-req-build-a7wt4kc1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/isadoranun/FATS /tmp/pip-req-build-a7wt4kc1\n",
            "  Running command git rev-parse -q --verify 'sha^aa81ce7f68d137798126b6e425dd069c3b4fde3a'\n",
            "  Running command git fetch -q https://github.com/isadoranun/FATS aa81ce7f68d137798126b6e425dd069c3b4fde3a\n",
            "  Running command git checkout -q aa81ce7f68d137798126b6e425dd069c3b4fde3a\n",
            "  Resolved https://github.com/isadoranun/FATS to commit aa81ce7f68d137798126b6e425dd069c3b4fde3a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from FATS==1.3.6) (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from FATS==1.3.6) (2.2.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from FATS==1.3.6) (0.14.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->FATS==1.3.6) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->FATS==1.3.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->FATS==1.3.6) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->FATS==1.3.6) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib->FATS==1.3.6) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->FATS==1.3.6) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->FATS==1.3.6) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->FATS==1.3.6) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->FATS==1.3.6) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->FATS==1.3.6) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->FATS==1.3.6) (2025.1)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.11/dist-packages (from statsmodels->FATS==1.3.6) (1.14.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->FATS==1.3.6) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->FATS==1.3.6) (1.17.0)\n",
            "Building wheels for collected packages: FATS\n",
            "  Building wheel for FATS (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for FATS: filename=FATS-1.3.6-py3-none-any.whl size=19323 sha256=27a4ef6700c524fa170b1a07d34959ddf9aaa18c81a90c7d75bd705a299a2d09\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/ca/1c/b2c0a2919d6d6b26cb4da9dcd41281adcfa630896623eae8ab\n",
            "Successfully built FATS\n",
            "Installing collected packages: FATS\n",
            "Successfully installed FATS-1.3.6\n"
          ]
        }
      ],
      "source": [
        "%pip install git+https://github.com/isadoranun/FATS@aa81ce7f68d137798126b6e425dd069c3b4fde3a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWZ8uiCgpweX"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import io\n",
        "import os\n",
        "from collections import Counter\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from warnings import filterwarnings\n",
        "\n",
        "import awscli\n",
        "import boto3\n",
        "\n",
        "import cudf\n",
        "import FATS\n",
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "#from imblearn.over_sampling import SMOTE\n",
        "#from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.utils import resample\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.layers import Conv1D, Dense, GlobalMaxPooling1D\n",
        "from tensorflow.keras.models import Sequential\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "r7Monk-UFQb7"
      },
      "outputs": [],
      "source": [
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore', category=RuntimeWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqF2kDWXwOmz",
        "outputId": "ab848e5b-df14-443a-9f34-aa53cfc49850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKDtqobKpweX"
      },
      "source": [
        "Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egfPXxwdpweY",
        "outputId": "ed604fc3-0b6a-4e6e-ad4c-8e9ead2a1c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AWS Access Key ID [None]: YCAJEwlvD7seR1kGiUHgc2XX3\n",
            "AWS Secret Access Key [None]: YCNMNFBWv2qBOkFJgoCsF-54lcmi00XI6PtjRMmG\n",
            "Default region name [None]: ru-cental1-a\n",
            "Default output format [None]: \n",
            "Page 0. 0 items processed.\n",
            "Page 50. 50000 items processed.\n",
            "Page 100. 100000 items processed.\n",
            "Page 150. 150000 items processed.\n",
            "Page 200. 200000 items processed.\n",
            "Page 250. 250000 items processed.\n",
            "Page 300. 300000 items processed.\n",
            "Page 350. 350000 items processed.\n",
            "Page 400. 400000 items processed.\n",
            "Page 450. 450000 items processed.\n",
            "Page 500. 500000 items processed.\n",
            "Page 550. 550000 items processed.\n",
            "Page 600. 600000 items processed.\n",
            "Page 650. 650000 items processed.\n",
            "Page 700. 700000 items processed.\n",
            "Page 750. 750000 items processed.\n",
            "Page 800. 800000 items processed.\n",
            "Page 850. 850000 items processed.\n",
            "Page 900. 900000 items processed.\n",
            "Page 950. 950000 items processed.\n",
            "Page 1000. 1000000 items processed.\n",
            "Page 1050. 1050000 items processed.\n",
            "Page 1100. 1100000 items processed.\n",
            "Page 1150. 1150000 items processed.\n",
            "Page 1200. 1200000 items processed.\n",
            "Page 1250. 1250000 items processed.\n",
            "Page 1300. 1300000 items processed.\n",
            "Page 1350. 1350000 items processed.\n",
            "Page 1400. 1400000 items processed.\n",
            "Page 1450. 1450000 items processed.\n"
          ]
        }
      ],
      "source": [
        "! aws configure\n",
        "s3 = boto3.client('s3', endpoint_url='https://storage.yandexcloud.net')\n",
        "bucket_name = 'guard-01'\n",
        "response= s3.list_objects_v2(Bucket=bucket_name, Delimiter='/')\n",
        "\n",
        "output_csv = \"filenames.csv\"\n",
        "with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    folders = [prefix['Prefix'] for prefix in response.get('CommonPrefixes', [])]\n",
        "    for folder in folders[2:]:\n",
        "        paginator = s3.get_paginator('list_objects_v2')\n",
        "        pages = paginator.paginate(Bucket=bucket_name, Prefix=folder)\n",
        "        objects = []\n",
        "\n",
        "        n_objects = 0\n",
        "        for i, page in enumerate(pages):\n",
        "            if 'Contents' in page:\n",
        "                if i % 50 == 0:\n",
        "                    print(f\"Page {i}. {n_objects} items processed.\")\n",
        "                n_objects += len(page['Contents'])\n",
        "                for obj in page['Contents']:\n",
        "                    if obj['Key'].endswith(\".csv\"):\n",
        "                        writer.writerow(obj['Key'].split('/')[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "efV137SnpweY",
        "outputId": "ad161e44-766f-4256-d50e-5b4c77c2f865"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asas_sn_id</th>\n",
              "      <th>main_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1002395</td>\n",
              "      <td>ECLIPSING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1003202</td>\n",
              "      <td>ECLIPSING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1003959</td>\n",
              "      <td>ECLIPSING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1004036</td>\n",
              "      <td>ECLIPSING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100590</td>\n",
              "      <td>ECLIPSING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494795</th>\n",
              "      <td>661428625363</td>\n",
              "      <td>xray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494796</th>\n",
              "      <td>661428693462</td>\n",
              "      <td>xray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494797</th>\n",
              "      <td>661428895304</td>\n",
              "      <td>xray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494798</th>\n",
              "      <td>8590170053</td>\n",
              "      <td>xray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494799</th>\n",
              "      <td>94489516525</td>\n",
              "      <td>xray</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1494800 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           asas_sn_id main_class\n",
              "0             1002395  ECLIPSING\n",
              "1             1003202  ECLIPSING\n",
              "2             1003959  ECLIPSING\n",
              "3             1004036  ECLIPSING\n",
              "4              100590  ECLIPSING\n",
              "...               ...        ...\n",
              "1494795  661428625363       xray\n",
              "1494796  661428693462       xray\n",
              "1494797  661428895304       xray\n",
              "1494798    8590170053       xray\n",
              "1494799   94489516525       xray\n",
              "\n",
              "[1494800 rows x 2 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('/content/filenames.csv', header=None)\n",
        "df.columns = ['main_class', 'asas_sn_id']\n",
        "df['asas_sn_id'] = df['asas_sn_id'].apply(lambda x: x.split('.')[0])\n",
        "df = df[['asas_sn_id', 'main_class']]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "z8kN6bG0pweZ",
        "outputId": "8c6cf868-bde8-41f3-ab65-74921f25f426"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>main_class</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ECLIPSING</th>\n",
              "      <td>578603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PULSATING</th>\n",
              "      <td>453156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ROTATING</th>\n",
              "      <td>434944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ERUPTIVE</th>\n",
              "      <td>13477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cataclysmic</th>\n",
              "      <td>8582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OTHERS</th>\n",
              "      <td>6000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xray</th>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "main_class\n",
              "ECLIPSING      578603\n",
              "PULSATING      453156\n",
              "ROTATING       434944\n",
              "ERUPTIVE        13477\n",
              "cataclysmic      8582\n",
              "OTHERS           6000\n",
              "xray               38\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['main_class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kTZlnPMcpweZ",
        "outputId": "207cf6d3-b6ec-42ff-eb7a-ab86d8ca5d84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to ASAS-SN Skypatrol!\n",
            "\n",
            "Current Deployment Version: 0.6.17 (26 JAN 2024)\n",
            "Please upgrade your client if not up to date.\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"client\",\n  \"rows\": 28,\n  \"fields\": [\n    {\n      \"column\": \"col_names\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"lii\",\n          \"max_mag_type\",\n          \"source_number\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dtypes\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"bigint\",\n          \"double\",\n          \"string\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col_names</th>\n",
              "      <th>dtypes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>asas_sn_id</td>\n",
              "      <td>bigint</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ra_deg</td>\n",
              "      <td>double</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dec_deg</td>\n",
              "      <td>double</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>source_number</td>\n",
              "      <td>bigint</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>name</td>\n",
              "      <td>string</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>variability_flag</td>\n",
              "      <td>bigint</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lii</td>\n",
              "      <td>double</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>bii</td>\n",
              "      <td>double</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>variability_type</td>\n",
              "      <td>string</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>max_mag_type</td>\n",
              "      <td>double</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>max_mag_limit</td>\n",
              "      <td>string</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>max_mag</td>\n",
              "      <td>double</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>max_mag_flag</td>\n",
              "      <td>string</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>max_mag_system</td>\n",
              "      <td>string</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>min_mag_type</td>\n",
              "      <td>string</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>min_mag_limit</td>\n",
              "      <td>string</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>min_mag</td>\n",
              "      <td>double</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>min_mag_flag</td>\n",
              "      <td>string</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>min_mag_system</td>\n",
              "      <td>string</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>epoch</td>\n",
              "      <td>double</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>epoch_flag</td>\n",
              "      <td>string</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>period_limit</td>\n",
              "      <td>string</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>period</td>\n",
              "      <td>double</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>period_flag</td>\n",
              "      <td>string</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>ref_bibcode_1</td>\n",
              "      <td>string</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>ref_bibcode_2</td>\n",
              "      <td>string</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>ref_bibcode_others</td>\n",
              "      <td>string</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>class</td>\n",
              "      <td>bigint</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             col_names  dtypes\n",
              "0           asas_sn_id  bigint\n",
              "1               ra_deg  double\n",
              "2              dec_deg  double\n",
              "3        source_number  bigint\n",
              "4                 name  string\n",
              "5     variability_flag  bigint\n",
              "6                  lii  double\n",
              "7                  bii  double\n",
              "8     variability_type  string\n",
              "9         max_mag_type  double\n",
              "10       max_mag_limit  string\n",
              "11             max_mag  double\n",
              "12        max_mag_flag  string\n",
              "13      max_mag_system  string\n",
              "14        min_mag_type  string\n",
              "15       min_mag_limit  string\n",
              "16             min_mag  double\n",
              "17        min_mag_flag  string\n",
              "18      min_mag_system  string\n",
              "19               epoch  double\n",
              "20          epoch_flag  string\n",
              "21        period_limit  string\n",
              "22              period  double\n",
              "23         period_flag  string\n",
              "24       ref_bibcode_1  string\n",
              "25       ref_bibcode_2  string\n",
              "26  ref_bibcode_others  string\n",
              "27               class  bigint"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyasassn.client import SkyPatrolClient\n",
        "client = SkyPatrolClient()\n",
        "client.catalogs.aavsovsx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u62EIDm-pweZ",
        "outputId": "66de8804-e173-4c40-bf40-2e0c21d293c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Создана переменная: df_eclipsing\n",
            "Создана переменная: df_rotating\n",
            "Создана переменная: df_pulsating\n",
            "Создана переменная: df_eruptive\n",
            "Создана переменная: df_cataclysmic\n",
            "Создана переменная: df_xray\n",
            "Создана переменная: df_others\n"
          ]
        }
      ],
      "source": [
        "Var_dict = {\n",
        "    'ECLIPSING':['E','EA','EB','E-DO','EP','EW','EC','ED','ESD','AR','BD','D','DM','DS','DW','EL','GS','HW','K','KE','KW','PN','SD','WD'],\n",
        "    'ROTATING': ['ACV','BY','CTTS','ROT','INT','IT','ELL','FKCOM','HB','LERI','PSR','R','ROT','RS','SXARI','SXARI','E','TTS','ROT','WTTS','ROT','NSIN', 'ELL','PSR','ROT','RS'],\n",
        "    'PULSATING':['ACEP', 'ACEP(B)', 'ACEPS', 'ACYG', 'BCEP', 'BCEPS', 'BLAP', 'BXCIR', 'CEP', 'CW', 'CWA', 'CWB', 'CWB(B)', 'CWBS', 'DCEP', 'DCEP(B)', 'CEP(B)', 'DCEPS', 'DCEPS(B)', 'DSCT', 'DSCTC', 'DWLYN', 'GDOR', 'HADS', 'HADS(B)', 'L', 'LB', 'LC', 'M', 'ORG', 'PPN', 'PVTEL', 'PVTELI', 'PVTELII', 'PVTELIII', 'roAm', 'roAp', 'ACVO', 'RR', 'RRAB', 'RRC', 'RRD', 'RR(B)', 'RV', 'RVA', 'RVB', 'SPB', 'LPB', 'SPBe', 'SR', 'SRA', 'SRB', 'SRC', 'SRD', 'SRS', 'SXPHE', 'SXPHE(B)', 'V361HYA', 'RPHS', 'V1093HER', 'ZZ', 'ZZA', 'ZZB', 'ZZ/GWLIB', 'ZZO', 'ZZLep', 'LPV', 'CW-FO', 'CW-FU', 'DCEP-FO', 'DCEP-FU', 'DSCTr', 'PULS', '(B)', 'BL', 'GWLIB', 'O'],\n",
        "    'ERUPTIVE':['BE', 'cPNB[e]', 'CTTS', 'DPV', 'DYPer', 'EXOR', 'FF', 'FSCMa', 'FUOR', 'FU', 'GCAS', 'I', 'IA', 'IB', 'IN', 'INA', 'INAT', 'INB', 'INS', 'INSA', 'INSB', 'INST', 'INT', 'IS', 'ISA', 'ISB', 'RCB', 'SDOR', 'TTS', 'UV', 'UVN', 'UXOR', 'WR', 'WTTS', 'ZZA/O', 'YSO', 'DIP', 'WR', '(YY)'],\n",
        "    'CATACLYSMIC':['AM', 'CBSS', 'CBSS/V', 'DQ', 'DQ/AE', 'IBWD', 'N', 'NA', 'NB', 'NC', 'NL', 'NL/VY', 'NR', 'SN', 'SN I', 'SN Ia', 'SN Iax', 'SN Ia-00cx-like', 'SN Ia-02es-like', 'SN Ia-06gz-like', 'SN Ia-86G-like', 'SN Ia-91bg-like', 'SN Ia-91T-like', 'SN Ia-99aa-like', 'SN Ia-Ca-rich', 'SN Ia-CSM', 'SN Ib', 'SN Ic', 'SN Icn', 'SN Ic-BL', 'SN Idn', 'SN Ien', 'SN II', 'SN IIa', 'SN IIb', 'SN IId', 'SN II-L', 'SN IIn', 'SN II-P', 'SN-pec', 'SLSN', 'SLSN-I', 'SLSN-II', 'UG', 'UGER', 'UGSS', 'UGSU', 'UGWZ', 'UGZ', 'UGZ/IW', 'V838MON', 'WDP', 'ZAND', 'CV', 'IBWD', 'V', 'VY'],\n",
        "    'XRAY':['HMXB', 'IMXB', 'LMXB', 'X', 'BHXB', 'XB', 'XJ', 'XN', 'XP', 'XPR', 'XBR'],\n",
        "    'others':['L:', 'S', '*'],\n",
        "}\n",
        "\n",
        "for key, value in Var_dict.items():\n",
        "    value = tuple(value)\n",
        "    query = f\"\"\"\n",
        "    SELECT\n",
        "    *\n",
        "    FROM aavsovsx\n",
        "    WHERE variability_type IN {value} and variability_flag=0\n",
        "    ORDER BY asas_sn_id\n",
        "    \"\"\"\n",
        "    df_name = f\"df_{key.lower()}\"\n",
        "    globals()[df_name] = client.adql_query(query)[['asas_sn_id', 'variability_type']]\n",
        "    print(f\"Создана переменная: {df_name}\")\n",
        "#lcs2 = client.adql_query(query)\n",
        "#eclip = lcs2[['asas_sn_id', 'variability_type']]\n",
        "#eclip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "B6menPPapwea",
        "outputId": "63409684-95e3-49ce-b812-21909e3d6769"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "conc"
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asas_sn_id</th>\n",
              "      <th>variability_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>421</td>\n",
              "      <td>EW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2445</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2546</td>\n",
              "      <td>EW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4618</td>\n",
              "      <td>EW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4998</td>\n",
              "      <td>EW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13585</th>\n",
              "      <td>661428965476</td>\n",
              "      <td>L:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13586</th>\n",
              "      <td>661428965524</td>\n",
              "      <td>L:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13587</th>\n",
              "      <td>661428965534</td>\n",
              "      <td>L:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13588</th>\n",
              "      <td>661428965590</td>\n",
              "      <td>L:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13589</th>\n",
              "      <td>661428965953</td>\n",
              "      <td>L:</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1162765 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         asas_sn_id variability_type\n",
              "0               421               EW\n",
              "1              2445                E\n",
              "2              2546               EW\n",
              "3              4618               EW\n",
              "4              4998               EW\n",
              "...             ...              ...\n",
              "13585  661428965476               L:\n",
              "13586  661428965524               L:\n",
              "13587  661428965534               L:\n",
              "13588  661428965590               L:\n",
              "13589  661428965953               L:\n",
              "\n",
              "[1162765 rows x 2 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conc = pd.concat([df_eclipsing, df_rotating, df_pulsating, df_eruptive, df_cataclysmic,\n",
        "           df_xray, df_others], axis=0)\n",
        "conc.drop_duplicates(inplace=True)\n",
        "conc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "EmPYs_iKpwea",
        "outputId": "6c8ab7c0-54b2-432c-f5f3-75e3a360e7aa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>asas_sn_id</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>main_class</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "asas_sn_id     int64\n",
              "main_class    object\n",
              "dtype: object"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['asas_sn_id'] = df['asas_sn_id'].astype('int64')\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXAKHgmgpwea",
        "outputId": "7aeb4430-f3b8-44cb-fb2c-46b5a8d5c249"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conc.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "RuLPsA0epwea",
        "outputId": "7819ca5e-0731-4fa1-a620-230b62a5b4ae"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_new"
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asas_sn_id</th>\n",
              "      <th>main_class</th>\n",
              "      <th>variability_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1002395</td>\n",
              "      <td>ECLIPSING</td>\n",
              "      <td>EW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1003202</td>\n",
              "      <td>ECLIPSING</td>\n",
              "      <td>EW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1003959</td>\n",
              "      <td>ECLIPSING</td>\n",
              "      <td>EW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1004036</td>\n",
              "      <td>ECLIPSING</td>\n",
              "      <td>EW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100590</td>\n",
              "      <td>ECLIPSING</td>\n",
              "      <td>EA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494798</th>\n",
              "      <td>661428625363</td>\n",
              "      <td>xray</td>\n",
              "      <td>HMXB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494799</th>\n",
              "      <td>661428693462</td>\n",
              "      <td>xray</td>\n",
              "      <td>X</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494800</th>\n",
              "      <td>661428895304</td>\n",
              "      <td>xray</td>\n",
              "      <td>HMXB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494801</th>\n",
              "      <td>8590170053</td>\n",
              "      <td>xray</td>\n",
              "      <td>HMXB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494802</th>\n",
              "      <td>94489516525</td>\n",
              "      <td>xray</td>\n",
              "      <td>HMXB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1494803 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           asas_sn_id main_class variability_type\n",
              "0             1002395  ECLIPSING               EW\n",
              "1             1003202  ECLIPSING               EW\n",
              "2             1003959  ECLIPSING               EW\n",
              "3             1004036  ECLIPSING               EW\n",
              "4              100590  ECLIPSING               EA\n",
              "...               ...        ...              ...\n",
              "1494798  661428625363       xray             HMXB\n",
              "1494799  661428693462       xray                X\n",
              "1494800  661428895304       xray             HMXB\n",
              "1494801    8590170053       xray             HMXB\n",
              "1494802   94489516525       xray             HMXB\n",
              "\n",
              "[1494803 rows x 3 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_new = pd.merge(df, conc, on='asas_sn_id', how='inner')\n",
        "df_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "Y9ozvDcYpwea",
        "outputId": "95ed76d2-a4a1-4c1a-d257-ff6c705e0035"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>main_class</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ECLIPSING</th>\n",
              "      <td>578604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PULSATING</th>\n",
              "      <td>453157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ROTATING</th>\n",
              "      <td>434945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ERUPTIVE</th>\n",
              "      <td>13477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cataclysmic</th>\n",
              "      <td>8582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OTHERS</th>\n",
              "      <td>6000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xray</th>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "main_class\n",
              "ECLIPSING      578604\n",
              "PULSATING      453157\n",
              "ROTATING       434945\n",
              "ERUPTIVE        13477\n",
              "cataclysmic      8582\n",
              "OTHERS           6000\n",
              "xray               38\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_new['main_class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "LViwwfhMpwea"
      },
      "outputs": [],
      "source": [
        "df_new.to_csv('id_mainclass_varclss.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "u2V4tdSNpwea",
        "outputId": "9ff1700b-b69c-4122-b672-d70a89ac3c39"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>asas_sn_id</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>main_class</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>variability_type</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "asas_sn_id          0\n",
              "main_class          0\n",
              "variability_type    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_new.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Y3lfrn-dpweb"
      },
      "outputs": [],
      "source": [
        "classes_for_model = {\"ECLIPSING\": [\"E\", \"EW\", \"EA\", \"EB\"],\n",
        "                    \"PULSATING\": [\"SR\", \"RRAB\", \"SRS\", \"RRC\", \"L\", \"M\",\n",
        "                                \"DSCT\", \"SRB\", \"HADS\", \"LB\", \"DCEP\"],\n",
        "                    \"ROTATING\": [\"ROT\", \"ELL\", \"RS\", \"BY\", \"ACV\"],\n",
        "                    \"ERUPTIVE\": [\"UV\", \"TTS\", \"GCAS\"],\n",
        "                    \"cataclysmic\": [\"UG\", \"UGSU\"]\n",
        "                    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "VwRNoKLYpweb"
      },
      "outputs": [],
      "source": [
        "# Создаем маску для фильтрации\n",
        "mask = df_new.apply(\n",
        "    lambda row: (\n",
        "        row[\"main_class\"] in classes_for_model  # Проверяем наличие класса в словаре\n",
        "        and row[\"variability_type\"] in classes_for_model[row[\"main_class\"]]  # Проверяем тип\n",
        "    ),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Применяем маску\n",
        "filtered_df = df_new[mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "qfhwI-5hpweb",
        "outputId": "3798cc6c-c5bc-4879-a15e-83bc15705dc5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "filtered_df"
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asas_sn_id</th>\n",
              "      <th>main_class</th>\n",
              "      <th>variability_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1002395</td>\n",
              "      <td>ECLIPSING</td>\n",
              "      <td>EW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1003202</td>\n",
              "      <td>ECLIPSING</td>\n",
              "      <td>EW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1003959</td>\n",
              "      <td>ECLIPSING</td>\n",
              "      <td>EW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1004036</td>\n",
              "      <td>ECLIPSING</td>\n",
              "      <td>EW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100590</td>\n",
              "      <td>ECLIPSING</td>\n",
              "      <td>EA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494754</th>\n",
              "      <td>94489523523</td>\n",
              "      <td>cataclysmic</td>\n",
              "      <td>UGSU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494756</th>\n",
              "      <td>94489954000</td>\n",
              "      <td>cataclysmic</td>\n",
              "      <td>UGSU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494758</th>\n",
              "      <td>94490107581</td>\n",
              "      <td>cataclysmic</td>\n",
              "      <td>UG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494759</th>\n",
              "      <td>94490226906</td>\n",
              "      <td>cataclysmic</td>\n",
              "      <td>UG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494762</th>\n",
              "      <td>94490585544</td>\n",
              "      <td>cataclysmic</td>\n",
              "      <td>UG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1023018 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          asas_sn_id   main_class variability_type\n",
              "0            1002395    ECLIPSING               EW\n",
              "1            1003202    ECLIPSING               EW\n",
              "2            1003959    ECLIPSING               EW\n",
              "3            1004036    ECLIPSING               EW\n",
              "4             100590    ECLIPSING               EA\n",
              "...              ...          ...              ...\n",
              "1494754  94489523523  cataclysmic             UGSU\n",
              "1494756  94489954000  cataclysmic             UGSU\n",
              "1494758  94490107581  cataclysmic               UG\n",
              "1494759  94490226906  cataclysmic               UG\n",
              "1494762  94490585544  cataclysmic               UG\n",
              "\n",
              "[1023018 rows x 3 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "AkDnfpQQpweb",
        "outputId": "2a25ac82-43f4-4df4-e108-4690221a5c20"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>main_class</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ECLIPSING</th>\n",
              "      <td>482169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PULSATING</th>\n",
              "      <td>435981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ROTATING</th>\n",
              "      <td>94703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cataclysmic</th>\n",
              "      <td>6323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ERUPTIVE</th>\n",
              "      <td>3842</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "main_class\n",
              "ECLIPSING      482169\n",
              "PULSATING      435981\n",
              "ROTATING        94703\n",
              "cataclysmic      6323\n",
              "ERUPTIVE         3842\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_df['main_class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "hBm0eZL8pweb"
      },
      "outputs": [],
      "source": [
        "filtered_df.to_csv('id_mainclass_varclss_filtered.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdlDUxK4pweb"
      },
      "source": [
        "Балансировка - UNDERsampling всех подклассов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "q2wymYsJpweb"
      },
      "outputs": [],
      "source": [
        "# Фильтрация данных\n",
        "\n",
        "balance_strategies = {\n",
        "            \"ECLIPSING\": {\n",
        "                \"under\": {\"E\": 10000, \"EW\": 10000, \"EA\": 6000, \"EB\": 2000},\n",
        "                \"remain\": {},\n",
        "                \"over\": {}\n",
        "            },\n",
        "            \"PULSATING\": {\n",
        "                \"under\": {\"SR\": 10000, \"RRAB\": 10000, \"SRS\": 10000, \"RRC\": 5000,\n",
        "                          \"L\": 5000, \"M\": 4000, \"DSCT\": 2000, \"SRB\": 1000,\n",
        "                          \"HADS\": 1000, \"LB\": 1000, \"DCEP\": 1000},\n",
        "                \"remain\": {},\n",
        "                \"over\": {}\n",
        "            },\n",
        "            \"ROTATING\": {\n",
        "                \"under\": {\"ROT\": 6000, \"ELL\": 4000,\n",
        "                         \"RS\": 2000, \"BY\": 1000, \"ACV\": 1000},\n",
        "                \"remain\": {},\n",
        "                \"over\": {}\n",
        "            },\n",
        "            \"ERUPTIVE\": {\n",
        "                \"under\": {\"UV\": 1000, \"TTS\": 1000},\n",
        "                \"remain\": {},\n",
        "                \"over\": {\"GCAS\": 1000}\n",
        "            },\n",
        "            \"cataclysmic\": {\n",
        "                \"under\": {\"UG\": 2000},\n",
        "                \"remain\": {},\n",
        "                \"over\": {\"UGSU\": 1000}\n",
        "            }\n",
        "            }\n",
        "\n",
        "balanced_ids = []\n",
        "\n",
        "for main_class, strategies in balance_strategies.items():\n",
        "    class_data = filtered_df[filtered_df[\"main_class\"] == main_class]\n",
        "\n",
        "    for strategy, subcl in strategies.items():\n",
        "        if strategy == 'under':\n",
        "            for sub, target in subcl.items():\n",
        "                subclass_data = class_data[class_data[\"variability_type\"] == sub]\n",
        "                subclass_data = resample(subclass_data, n_samples=target, random_state=42, replace=False)\n",
        "                balanced_ids.extend(subclass_data[\"asas_sn_id\"].tolist())\n",
        "        else:\n",
        "            for sub, target in subcl.items():\n",
        "                subclass_data = class_data[class_data[\"variability_type\"] == sub]\n",
        "                balanced_ids.extend(subclass_data[\"asas_sn_id\"].tolist())\n",
        "\n",
        "balanced_labels = filtered_df[filtered_df[\"asas_sn_id\"].isin(balanced_ids)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "id": "o8zpkqGKpweb",
        "outputId": "f42ac80d-1b88-4904-b9ab-9884371a8c8a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"filtered_df\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"main_class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ROTATING\",\n          \"ECLIPSING\",\n          \"cataclysmic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"variability_type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"UV\",\n          \"HADS\",\n          \"EW\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"asas_sn_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 73737,\n        \"min\": 800,\n        \"max\": 338364,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          1845,\n          2585,\n          83233\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>asas_sn_id</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>main_class</th>\n",
              "      <th>variability_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">ECLIPSING</th>\n",
              "      <th>E</th>\n",
              "      <td>338364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EA</th>\n",
              "      <td>49312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EB</th>\n",
              "      <td>11260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EW</th>\n",
              "      <td>83233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">ERUPTIVE</th>\n",
              "      <th>GCAS</th>\n",
              "      <td>942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TTS</th>\n",
              "      <td>1055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UV</th>\n",
              "      <td>1845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">PULSATING</th>\n",
              "      <th>DCEP</th>\n",
              "      <td>2277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DSCT</th>\n",
              "      <td>5972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HADS</th>\n",
              "      <td>2585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L</th>\n",
              "      <td>33486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LB</th>\n",
              "      <td>2470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>M</th>\n",
              "      <td>20380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RRAB</th>\n",
              "      <td>90026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RRC</th>\n",
              "      <td>34751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SR</th>\n",
              "      <td>166584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SRB</th>\n",
              "      <td>3540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SRS</th>\n",
              "      <td>73910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">ROTATING</th>\n",
              "      <th>ACV</th>\n",
              "      <td>1397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BY</th>\n",
              "      <td>3393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ELL</th>\n",
              "      <td>25436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ROT</th>\n",
              "      <td>59419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RS</th>\n",
              "      <td>5058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">cataclysmic</th>\n",
              "      <th>UG</th>\n",
              "      <td>5523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UGSU</th>\n",
              "      <td>800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              asas_sn_id\n",
              "main_class  variability_type            \n",
              "ECLIPSING   E                     338364\n",
              "            EA                     49312\n",
              "            EB                     11260\n",
              "            EW                     83233\n",
              "ERUPTIVE    GCAS                     942\n",
              "            TTS                     1055\n",
              "            UV                      1845\n",
              "PULSATING   DCEP                    2277\n",
              "            DSCT                    5972\n",
              "            HADS                    2585\n",
              "            L                      33486\n",
              "            LB                      2470\n",
              "            M                      20380\n",
              "            RRAB                   90026\n",
              "            RRC                    34751\n",
              "            SR                    166584\n",
              "            SRB                     3540\n",
              "            SRS                    73910\n",
              "ROTATING    ACV                     1397\n",
              "            BY                      3393\n",
              "            ELL                    25436\n",
              "            ROT                    59419\n",
              "            RS                      5058\n",
              "cataclysmic UG                      5523\n",
              "            UGSU                     800"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# до\n",
        "filtered_df.groupby(['main_class','variability_type']).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "id": "WzUZFK-fpweb",
        "outputId": "4f1abdfa-4545-490c-fe2c-a6dfd2243947"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"balanced_labels\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"main_class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ROTATING\",\n          \"ECLIPSING\",\n          \"cataclysmic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"variability_type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"UV\",\n          \"HADS\",\n          \"EW\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"asas_sn_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3520,\n        \"min\": 800,\n        \"max\": 10000,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4000,\n          942,\n          10000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>asas_sn_id</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>main_class</th>\n",
              "      <th>variability_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">ECLIPSING</th>\n",
              "      <th>E</th>\n",
              "      <td>10000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EA</th>\n",
              "      <td>6000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EB</th>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EW</th>\n",
              "      <td>10000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">ERUPTIVE</th>\n",
              "      <th>GCAS</th>\n",
              "      <td>942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TTS</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UV</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">PULSATING</th>\n",
              "      <th>DCEP</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DSCT</th>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HADS</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L</th>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LB</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>M</th>\n",
              "      <td>4000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RRAB</th>\n",
              "      <td>10000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RRC</th>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SR</th>\n",
              "      <td>10000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SRB</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SRS</th>\n",
              "      <td>10000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">ROTATING</th>\n",
              "      <th>ACV</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BY</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ELL</th>\n",
              "      <td>4000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ROT</th>\n",
              "      <td>6000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RS</th>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">cataclysmic</th>\n",
              "      <th>UG</th>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UGSU</th>\n",
              "      <td>800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              asas_sn_id\n",
              "main_class  variability_type            \n",
              "ECLIPSING   E                      10000\n",
              "            EA                      6000\n",
              "            EB                      2000\n",
              "            EW                     10000\n",
              "ERUPTIVE    GCAS                     942\n",
              "            TTS                     1000\n",
              "            UV                      1000\n",
              "PULSATING   DCEP                    1000\n",
              "            DSCT                    2000\n",
              "            HADS                    1000\n",
              "            L                       5000\n",
              "            LB                      1000\n",
              "            M                       4000\n",
              "            RRAB                   10000\n",
              "            RRC                     5000\n",
              "            SR                     10000\n",
              "            SRB                     1000\n",
              "            SRS                    10000\n",
              "ROTATING    ACV                     1000\n",
              "            BY                      1000\n",
              "            ELL                     4000\n",
              "            ROT                     6000\n",
              "            RS                      2000\n",
              "cataclysmic UG                      2000\n",
              "            UGSU                     800"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# после\n",
        "balanced_labels.groupby(['main_class','variability_type']).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "5oEdIEWj4523"
      },
      "outputs": [],
      "source": [
        "balanced_labels.to_csv('balanced_labels.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LANL2Yv1pwec"
      },
      "source": [
        "Объединенная подготовка для извлечения FATS признаков и подготовка данных для CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsyR-Mv9pwec"
      },
      "outputs": [],
      "source": [
        "class S3TimeSeriesProcessor:\n",
        "    \"\"\"Processes astronomical time series data from S3 storage for different ML tasks.\n",
        "\n",
        "    Handles CSV files containing light curve data, supporting:\n",
        "    - Feature extraction for traditional ML\n",
        "    - Data preparation for CNN models\n",
        "    - Combined processing modes\n",
        "\n",
        "    Args:\n",
        "        bucket_name (str): Name of S3 bucket containing source data\n",
        "        aws_access_key_id (str): AWS-compatible access key for S3 auth\n",
        "        aws_secret_access_key (str): AWS-compatible secret key for S3 auth\n",
        "\n",
        "    Attributes:\n",
        "        s3 (boto3.client): Configured S3 client with Yandex Cloud endpoint\n",
        "        bucket (str): Target bucket name for all operations\n",
        "        scaler (StandardScaler): Scaler instance for data normalization\n",
        "\n",
        "    Methods:\n",
        "        process_prefix: Main processing method for S3 prefixes\n",
        "        jd_to_mjd: Static method for Julian Day conversion\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    def __init__(self, bucket_name, aws_access_key_id, aws_secret_access_key):\n",
        "        \"\"\"Initializes S3 client and processing components.\"\"\"\n",
        "        self.s3 = boto3.client('s3',\n",
        "                             aws_access_key_id=aws_access_key_id,\n",
        "                             aws_secret_access_key=aws_secret_access_key,\n",
        "                             endpoint_url='https://storage.yandexcloud.net')\n",
        "        self.bucket = bucket_name\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def jd_to_mjd(jd):\n",
        "        \"\"\"Converts Julian Day to Modified Julian Day (MJD).\n",
        "\n",
        "        Args:\n",
        "            jd (float): Julian Day value\n",
        "\n",
        "        Returns:\n",
        "            float: MJD value. Returns NaN for invalid inputs (negative/NaN JD).\n",
        "\n",
        "        Formula:\n",
        "            MJD = JD - 2,400,000.5\n",
        "        \"\"\"\n",
        "        if np.isnan(jd) or jd < 0:\n",
        "            return np.nan\n",
        "        return jd - 2400000.5\n",
        "\n",
        "\n",
        "    def _process_file(self, file_key, processing_type, max_length=100):\n",
        "        \"\"\"Internal method for processing individual S3 files.\n",
        "\n",
        "        Args:\n",
        "            file_key (str): Full S3 object key/path\n",
        "            processing_type (str): Processing mode - 'features', 'cnn', or 'both'\n",
        "            max_length (int): Sequence length for CNN padding (default: 100)\n",
        "\n",
        "        Returns:\n",
        "            varies: Based on processing_type:\n",
        "                - 'features': pandas.DataFrame with extracted features\n",
        "                - 'cnn': numpy.ndarray of shaped (max_length, 2)\n",
        "                - 'both': dict with 'features' and 'cnn_data' keys\n",
        "                - None for invalid files/processing errors\n",
        "\n",
        "        Note:\n",
        "            - Performs common preprocessing: NaN removal, JD->MJD conversion\n",
        "            - Requires CSV format with header row and columns: mag, jd, mag_err\n",
        "            - Skips files with <10 valid observations after preprocessing\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Загрузка и базовый препроцессинг\n",
        "            response = self.s3.get_object(Bucket=self.bucket, Key=file_key)\n",
        "            content = response['Body'].read().decode('utf-8')\n",
        "            df = pd.read_csv(io.StringIO(content), header=1)\n",
        "\n",
        "            # Общая предобработка\n",
        "            df = df[['mag', 'jd', 'mag_err']].dropna(how='any', axis=0).\\\n",
        "                                              drop_duplicates(subset='jd')\n",
        "\n",
        "            mask = (\n",
        "                np.isfinite(df['mag']) &\n",
        "                np.isfinite(df['jd']) &\n",
        "                np.isfinite(df['mag_err'])\n",
        "            )\n",
        "            df = df[mask].copy()\n",
        "            if df.empty:\n",
        "                return None, None\n",
        "\n",
        "            df.loc[:, 'jd'] = df.loc[:, 'jd'].apply(self.jd_to_mjd)\n",
        "            df = df.dropna(subset=['jd'], how='any').sort_values('jd')\n",
        "\n",
        "            # Если слишком мало данных в файле\n",
        "            if len(df) < 10:\n",
        "                return None, None\n",
        "\n",
        "            # Разделение обработки\n",
        "            if processing_type == 'features':\n",
        "                return self._extract_features(df, file_key)\n",
        "\n",
        "            elif processing_type == 'cnn':\n",
        "                return self._prepare_cnn_data(df, max_length)\n",
        "\n",
        "            elif processing_type == 'both':\n",
        "                features = self._extract_features(df, file_key, return_df=True)\n",
        "                cnn_data = self._prepare_cnn_data(df, max_length)\n",
        "                return {**(features if features is not None else {}), 'cnn_data': cnn_data}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_key}: {str(e)}\")\n",
        "            return None, None\n",
        "\n",
        "\n",
        "    def _extract_features(self, df, file_key, return_df=False):\n",
        "        \"\"\"Internal feature extraction using FATS library.\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): Preprocessed light curve data\n",
        "            file_key (str): Source file path for ID extraction\n",
        "            return_df (bool): Whether to return raw data (default: False)\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame/None: Features DataFrame, or None on failure\n",
        "            dict/None: If return_df=True, adds raw data arrays under 'raw_data'\n",
        "\n",
        "        Note:\n",
        "            Computes 17 statistical features using FATS library\n",
        "            Object ID is extracted from filename (basename without extension)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            mag = df['mag'].values\n",
        "            time = df['jd'].values\n",
        "            error = df['mag_err'].values\n",
        "\n",
        "            preprocessed_data = FATS.Preprocess_LC(mag, time, error)\n",
        "            mag, time, error = preprocessed_data.Preprocess()\n",
        "\n",
        "            features = FATS.FeatureSpace(\n",
        "                featureList=['Amplitude','Mean','Std','Skew','MedianAbsDev'\n",
        "                                ,'PeriodLS','Period_fit','Freq1_harmonics_amplitude_0',\n",
        "                                'FluxPercentileRatioMid20','FluxPercentileRatioMid80',\n",
        "                                'PercentAmplitude','LinearTrend','MaxSlope',\n",
        "                                'SlottedA_length','StructureFunction_index_21',\n",
        "                                'Autocor_length', 'StetsonK'],\n",
        "                Data=['magnitude', 'time', 'error']\n",
        "            ).calculateFeature(np.vstack([mag, time, error])).result(method='dict')\n",
        "\n",
        "            file_id = file_key.split('/')[-1].split('.')[0]\n",
        "            features_df = pd.DataFrame([features]).assign(object_id=file_id)\n",
        "\n",
        "            return features_df if not return_df else {\n",
        "                'features': features_df,\n",
        "                'raw_data': (mag, time, error)\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            #print(f\"Feature extraction failed for {file_key}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "    def _prepare_cnn_data(self, df, max_length):\n",
        "        \"\"\"Internal method for CNN input preparation.\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): Preprocessed light curve data\n",
        "            max_length (int): Target sequence length\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: Shaped (max_length, 2) array containing:\n",
        "                - StandardScaler-normalized [mag, mag_err] values\n",
        "                - Zero-padded if shorter than max_length\n",
        "                - Truncated if longer than max_length\n",
        "        \"\"\"\n",
        "        scaled = self.scaler.fit_transform(df[['mag', 'mag_err']])\n",
        "\n",
        "        if len(scaled) > max_length:\n",
        "            padded = scaled[:max_length]\n",
        "        else:\n",
        "            padded = np.pad(scaled,\n",
        "                          ((0, max_length - len(scaled)), (0, 0)),\n",
        "                          mode='constant',\n",
        "                          constant_values=0)\n",
        "        return padded\n",
        "\n",
        "\n",
        "    def process_prefix(self, prefix, ids_list, processing_type='both', max_length=100):\n",
        "        \"\"\"Processes all files in S3 prefix matching object IDs.\n",
        "\n",
        "        Args:\n",
        "            prefix (str): S3 prefix (folder path) to process\n",
        "            ids_list (list[int]): List of numeric object IDs to include\n",
        "            processing_type (str): One of ['features', 'cnn', 'both'] (default: 'both')\n",
        "            max_length (int): Padding length for CNN data (default: 100)\n",
        "\n",
        "        Returns:\n",
        "            tuple: (features_df, cnn_data) where:\n",
        "                - features_df: pandas.DataFrame of extracted features (None if empty)\n",
        "                - cnn_data: numpy.ndarray of shaped (n_samples, max_length, 2) (None if empty)\n",
        "\n",
        "        Note:\n",
        "            - Saves results to S3 automatically:\n",
        "                - Features: {prefix}/features.csv\n",
        "                - CNN data: {prefix}/cnn_data.npz\n",
        "            - Uses pagination to handle large prefix contents\n",
        "            - Processes ~50 files before printing progress update\n",
        "            - Skips files with invalid formats/non-numeric names\n",
        "        \"\"\"\n",
        "        features_df = pd.DataFrame()\n",
        "        cnn_data = []\n",
        "        ids = []\n",
        "        i=0\n",
        "\n",
        "        try:\n",
        "            paginator = self.s3.get_paginator('list_objects_v2')\n",
        "            page_iterator = paginator.paginate(Bucket=self.bucket, Prefix=prefix)\n",
        "\n",
        "            for page in page_iterator:\n",
        "                if 'Contents' not in page:\n",
        "                    print(f\"Префикс '{prefix}' не содержит объектов. Пропускаю...\")\n",
        "                    continue\n",
        "\n",
        "                for obj in page['Contents']:\n",
        "                    file_key = obj['Key']\n",
        "                    if not file_key.endswith('.csv'):\n",
        "                        continue\n",
        "\n",
        "                    try:\n",
        "                      file_id = int(file_key.split('/')[-1].split('.')[0])\n",
        "                    except ValueError:\n",
        "                      print(f\"Skipping invalid file: {file_key}\")\n",
        "                      continue\n",
        "                    if file_id not in ids_list:\n",
        "                      continue\n",
        "\n",
        "                    result = self._process_file(file_key, processing_type, max_length)\n",
        "                    i+=1\n",
        "                    if i % 50 == 0:\n",
        "                      print(f\"{i} items processed.\")\n",
        "\n",
        "                    if result is None:\n",
        "                        continue\n",
        "\n",
        "                    if processing_type == 'features':\n",
        "                        features_df = pd.concat([features_df, result], ignore_index=True)\n",
        "                    elif processing_type == 'cnn':\n",
        "                        cnn_data.append(result)\n",
        "                        ids.append(str(file_id))\n",
        "                    elif processing_type == 'both':\n",
        "                        if 'features' not in result or 'cnn_data' not in result:\n",
        "                            continue\n",
        "                        features_df = pd.concat([features_df, result['features']], ignore_index=True)\n",
        "                        cnn_data.append(result['cnn_data'])\n",
        "                        ids.append(str(file_id))\n",
        "\n",
        "\n",
        "            # Сохранение результатов\n",
        "            if processing_type in ['features', 'both'] and not features_df.empty:\n",
        "                csv_buffer = io.StringIO()\n",
        "                features_df.to_csv(csv_buffer, index=False)\n",
        "                self.s3.put_object(\n",
        "                    Bucket=self.bucket,\n",
        "                    Key=f\"{prefix}/features.csv\",\n",
        "                    Body=csv_buffer.getvalue()\n",
        "                )\n",
        "\n",
        "            if processing_type in ['cnn', 'both'] and cnn_data:\n",
        "                with io.BytesIO() as buffer:\n",
        "                    np.savez(buffer,\n",
        "                            X=np.array(cnn_data),\n",
        "                            ids=np.array(ids))\n",
        "                    buffer.seek(0)\n",
        "                    self.s3.put_object(\n",
        "                        Bucket=self.bucket,\n",
        "                        Key=f\"{prefix}/cnn_data.npz\",\n",
        "                        Body=buffer.getvalue()\n",
        "                    )\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка при обработке префикса {prefix, file_key}: {str(e)}\")\n",
        "\n",
        "        features_result = features_df if not features_df.empty else None\n",
        "        cnn_result = np.array(cnn_data) if cnn_data else None\n",
        "        return (features_result, cnn_result)\n",
        "\n",
        "\n",
        "\n",
        "# Варианты обработки:\n",
        "#processor = S3TimeSeriesProcessor('your-bucket-name', aws_access_key_id, aws_secret_access_key)\n",
        "# 1. Только фичи\n",
        "#features_df, _ = processor.process_prefix('raw_data/', ids, processing_type='features')\n",
        "# 2. Только данные для CNN\n",
        "#_, cnn_data = processor.process_prefix('raw_data/', ids, processing_type='cnn')\n",
        "# 3. Оба варианта одновременно\n",
        "#full_features, full_cnn = processor.process_prefix('raw_data/', ids, processing_type='both')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cDvQ1bM5rz_"
      },
      "outputs": [],
      "source": [
        "# Настройки S3\n",
        "aws_access_key_id = os.getenv('aws_access_key_id')\n",
        "aws_secret_access_key = os.getenv('aws_secret_access_key')\n",
        "S3_BUCKET = 'guard-01'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "OIIEBe1hpwec",
        "outputId": "4254fab6-f6f3-41a4-d648-337cff309142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50 items processed.\n",
            "100 items processed.\n",
            "150 items processed.\n",
            "200 items processed.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-0c436706ef3e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdf_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"df_{pref.replace('/', '_')}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       features, cnn = processor.process_prefix(pref, \n\u001b[0m\u001b[1;32m     15\u001b[0m                                                 \u001b[0mids_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                                 processing_type='both')\n",
            "\u001b[0;32m<ipython-input-46-30757ee4309a>\u001b[0m in \u001b[0;36mprocess_prefix\u001b[0;34m(self, prefix, ids_list, processing_type, max_length)\u001b[0m\n\u001b[1;32m    131\u001b[0m                       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessing_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m                     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-30757ee4309a>\u001b[0m in \u001b[0;36m_process_file\u001b[0;34m(self, file_key, processing_type, max_length)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mprocessing_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'both'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0mcnn_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_cnn_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cnn_data'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcnn_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-30757ee4309a>\u001b[0m in \u001b[0;36m_extract_features\u001b[0;34m(self, df, file_key, return_df)\u001b[0m\n\u001b[1;32m     77\u001b[0m                                 'Autocor_length', 'StetsonK'],\n\u001b[1;32m     78\u001b[0m                 \u001b[0mData\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'magnitude'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             ).calculateFeature(np.vstack([mag, time, error])).result(method='dict')\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mfile_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/FATS/Feature.py\u001b[0m in \u001b[0;36mcalculateFeature\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatureFunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/FATS/FeatureFunctionLib.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m             \u001b[0mwk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwk2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlomb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfasper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagnitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0mfundamental_Freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwk1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjmax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/FATS/lomb.py\u001b[0m in \u001b[0;36mfasper\u001b[0;34m(x, y, ofac, hifac, MACC)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;31m# Take the Fast Fourier Transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mwk1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mifft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwk1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwk1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mwk2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mifft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwk2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwk1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mwk1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwk1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnout\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/fft/_pocketfft.py\u001b[0m in \u001b[0;36mifft\u001b[0;34m(a, n, axis, norm)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0minv_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_backward_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_raw_fft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/fft/_pocketfft.py\u001b[0m in \u001b[0;36m_raw_fft\u001b[0;34m(a, n, axis, is_real, is_forward, inv_norm)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpfi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Основной процесс выполнения\n",
        "ids = (balanced_labels['asas_sn_id'].values).tolist()\n",
        "prefixs = ['variables/ECLIPSING/', 'variables/ERUPTIVE/',\n",
        "           'variables/PULSATING/', 'variables/ROTATING/',\n",
        "           'variables/cataclysmic/']\n",
        "\n",
        "processor = S3TimeSeriesProcessor(S3_BUCKET,\n",
        "                                  aws_access_key_id,\n",
        "                                  aws_secret_access_key)\n",
        "\n",
        "for pref in prefixs:\n",
        "    df_name = f\"df_{pref.replace('/', '_')}\"\n",
        "    try:\n",
        "      features, cnn = processor.process_prefix(pref,\n",
        "                                                ids_list=ids,\n",
        "                                                processing_type='both')\n",
        "\n",
        "\n",
        "      if features is not None and not features.empty:\n",
        "        print(f\"Обработано объектов: {len(features)}\")\n",
        "\n",
        "      if cnn is not None:\n",
        "        print(f\"CNN данных: {cnn.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при обработке папки {pref}: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4MdJ8hcpwec"
      },
      "source": [
        "Оценка модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTmV7FwRpwec"
      },
      "outputs": [],
      "source": [
        "def evaluate_hierarchical(y_true_main, y_true_sub, main_preds, sub_preds,\n",
        "                          le_main, le_sub):\n",
        "    \"\"\"Generates classification reports for hierarchical main/sub-class predictions.\n",
        "\n",
        "    Evaluates performance of a two-level hierarchical classification system by\n",
        "    producing standardized metrics reports for both classification levels.\n",
        "\n",
        "    Args:\n",
        "        y_true_main (array-like): Encoded true labels for main classes\n",
        "        y_true_sub (array-like): Encoded true labels for sub-classes\n",
        "        main_preds (list[tuple]): Main level predictions as list of (label, confidence) tuples\n",
        "        sub_preds (list[tuple]): Sub-level predictions as list of (label, confidence) tuples\n",
        "        le_main (LabelEncoder): Trained LabelEncoder for main class labels\n",
        "        le_sub (LabelEncoder): Trained LabelEncoder for sub-class labels\n",
        "\n",
        "    Returns:\n",
        "        tuple[dict, dict]: Two classification report dictionaries:\n",
        "            - main_report: Metrics for main classes (precision/recall/F1)\n",
        "            - sub_report: Metrics for sub-classes (precision/recall/F1)\n",
        "    \"\"\"\n",
        "    # Преобразование числовых меток в оригинальные названия\n",
        "    y_main_true_labels = le_main.inverse_transform(y_true_main)\n",
        "    y_sub_true_labels = le_sub.inverse_transform(y_true_sub)\n",
        "\n",
        "    # Извлечение предсказанных меток\n",
        "    main_pred_labels = [pred[0] for pred in main_preds]\n",
        "    sub_pred_labels = [pred[0] for pred in sub_preds]\n",
        "\n",
        "    # Сбор всех уникальных меток для корректного отображения в отчете\n",
        "    all_main_labels = list(set(y_main_true_labels) | set(main_pred_labels))\n",
        "    all_sub_labels = list(set(y_sub_true_labels) | set(sub_pred_labels))\n",
        "\n",
        "    # Генерация отчетов\n",
        "    print(\"\\nMAIN CLASSES REPORT:\")\n",
        "    print(classification_report(\n",
        "        y_main_true_labels,\n",
        "        main_pred_labels,\n",
        "        labels=all_main_labels,\n",
        "        zero_division=0\n",
        "    ))\n",
        "\n",
        "    print(\"\\nSUB CLASSES REPORT:\")\n",
        "    print(classification_report(\n",
        "        y_sub_true_labels,\n",
        "        sub_pred_labels,\n",
        "        labels=all_sub_labels,\n",
        "        zero_division=0\n",
        "    ))\n",
        "\n",
        "    # Возврат метрик в виде словарей\n",
        "    main_report = classification_report(\n",
        "        y_main_true_labels,\n",
        "        main_pred_labels,\n",
        "        labels=all_main_labels,\n",
        "        output_dict=True,\n",
        "        zero_division=0\n",
        "    )\n",
        "\n",
        "    sub_report = classification_report(\n",
        "        y_sub_true_labels,\n",
        "        sub_pred_labels,\n",
        "        labels=all_sub_labels,\n",
        "        output_dict=True,\n",
        "        zero_division=0\n",
        "    )\n",
        "\n",
        "    return main_report, sub_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M5VJsyZpwec"
      },
      "source": [
        "Иерархическое предсказание с классом \"другие\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zic5EI6apwed"
      },
      "outputs": [],
      "source": [
        "def hierarchical_predict_with_proba(X, lgb_main, le_main,\n",
        "                                    subclass_models, le_sub,\n",
        "                                    MAIN_THRESHOLD, SUB_THRESHOLD):\n",
        "    \"\"\"Performs hierarchical classification with confidence-based fallback.\n",
        "\n",
        "    Implements two-stage prediction with probabilistic thresholds:\n",
        "    1. Main class prediction with 'OTHER' fallback\n",
        "    2. Subclass prediction conditioned on main class results\n",
        "\n",
        "    Args:\n",
        "        X (array-like): Input features array of shape (n_samples, n_features)\n",
        "        lgb_main (LGBMClassifier): Trained LightGBM model for main classes\n",
        "        le_main (LabelEncoder): LabelEncoder for main class labels\n",
        "        subclass_models (dict): Dictionary mapping {main_label: sub_model} \n",
        "            where sub_model is trained on corresponding subclasses\n",
        "        le_sub (LabelEncoder): LabelEncoder for all possible subclass labels\n",
        "        MAIN_THRESHOLD (float): Confidence threshold [0-1] for accepting main \n",
        "            class prediction (else 'OTHER')\n",
        "        SUB_THRESHOLD (float): Confidence threshold [0-1] for accepting subclass\n",
        "            prediction (else 'CLASS_OTHER')\n",
        "\n",
        "    Returns:\n",
        "        tuple: \n",
        "            - main_results (list[tuple]): (predicted_label, confidence) for main classes\n",
        "            - sub_results (list[tuple]): (predicted_label, confidence) for subclasses\n",
        "\n",
        "    Note:\n",
        "        - 'OTHER' handling:\n",
        "            - Main level: Used when no class meets confidence threshold\n",
        "            - Sub level: Used when either main is OTHER or subclass confidence is low\n",
        "            - Subclass OTHER labels inherit parent class (e.g: 'CLASS_OTHER')\n",
        "        - Confidence scores represent:\n",
        "            - For accepted predictions: model's maximum class probability\n",
        "            - For 'OTHER' predictions: 1 - max_prob (inverse confidence)\n",
        "        - Subclass predictions only attempt if main class isn't OTHER and has a model\n",
        "    \"\"\"\n",
        "    # Уровень 1: Основные классы\n",
        "    main_proba = lgb_main.predict_proba(X)\n",
        "    main_results = []\n",
        "\n",
        "    for proba in main_proba:\n",
        "        max_prob = np.max(proba)\n",
        "        main_class_idx = np.argmax(proba)\n",
        "\n",
        "        if max_prob > MAIN_THRESHOLD:\n",
        "            main_label = le_main.classes_[main_class_idx]\n",
        "            main_confidence = max_prob\n",
        "        else:\n",
        "            main_label = 'OTHER'\n",
        "            main_confidence = 1 - max_prob  # Уверенность в \"другости\"\n",
        "\n",
        "        main_results.append((main_label, main_confidence))\n",
        "\n",
        "    # Уровень 2: Подклассы\n",
        "    sub_results = []\n",
        "    for i, (main_label, main_conf) in enumerate(main_results):\n",
        "        if main_label == 'OTHER':\n",
        "            sub_results.append(('OTHER', 1.0))  # 100% уверенности в OTHER для подкласса\n",
        "            continue\n",
        "\n",
        "        if main_label not in subclass_models:\n",
        "            sub_label = f'{main_label}_OTHER'\n",
        "            sub_results.append((sub_label, 1.0))\n",
        "            continue\n",
        "\n",
        "        model = subclass_models[main_label]\n",
        "        sub_proba = model.predict_proba(X[i].reshape(1, -1))[0]\n",
        "        max_sub_prob = np.max(sub_proba)\n",
        "        sub_class_idx = np.argmax(sub_proba)\n",
        "\n",
        "        if max_sub_prob > SUB_THRESHOLD:\n",
        "            sub_label = le_sub.classes_[sub_class_idx]\n",
        "            sub_confidence = max_sub_prob\n",
        "        else:\n",
        "            sub_label = f'{main_label}_OTHER'\n",
        "            sub_confidence = 1 - max_sub_prob\n",
        "\n",
        "        sub_results.append((sub_label, sub_confidence))\n",
        "\n",
        "    return main_results, sub_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFFPTgaQpwed"
      },
      "source": [
        "Иерархическая модель с объединением признаков (CNN + LightGBM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C33nKQj1pwed"
      },
      "outputs": [],
      "source": [
        "# Загрузка обработанных данных из S3 после выполнения process_prefix\n",
        "# объединить данные папок и сделать shuffle, побавить по индексам y\n",
        "features_df =\n",
        "cnn_arrays ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0ViVbxQpwed"
      },
      "outputs": [],
      "source": [
        "# Подготовка данных для модели\n",
        "# Для FATS-фичей\n",
        "scaler_fats = StandardScaler()\n",
        "X_fats = scaler_fats.fit_transform(features_df.drop('object_id', axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBTU40fwpwed"
      },
      "outputs": [],
      "source": [
        "# Для временных признаков cnn\n",
        "X_ts = np.array([\n",
        "    np.column_stack((row['mag'], row['mag_err']))\n",
        "    for _, row in cnn_arrays.iterrows()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EI6bFpRpwed"
      },
      "outputs": [],
      "source": [
        "# Кодирование целевых переменных\n",
        "le_main = LabelEncoder()\n",
        "le_sub = LabelEncoder()\n",
        "y_main = le_main.fit_transform(balanced_labels['main_class'])\n",
        "y_sub = le_sub.fit_transform(balanced_labels['variability_type'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TtvfFpupwed"
      },
      "outputs": [],
      "source": [
        "def build_supervised_cnn(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv1D(64, kernel_size=5, activation='relu',\n",
        "               padding='same', input_shape=input_shape),\n",
        "        Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(256, activation='relu', name=\"embeddings\"), # Слой для эмбеддингов\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvV8feGVpwed"
      },
      "outputs": [],
      "source": [
        "# input_shape с 2 каналами\n",
        "input_shape = (X_ts.shape[1], X_ts.shape[2])  # (500, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAh8zmaipwed"
      },
      "outputs": [],
      "source": [
        "# Создаем и компилируем модель\n",
        "num_main_classes = len(le_main.classes_)\n",
        "cnn_model = build_supervised_cnn((X_ts.shape[1], X_ts.shape[2]), num_main_classes)\n",
        "cnn_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss={\n",
        "        'dense_1': 'sparse_categorical_crossentropy'  # Название выходного слоя\n",
        "    },\n",
        "    metrics={'dense_1': 'accuracy'}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_0M_GPqpwed"
      },
      "outputs": [],
      "source": [
        "# Обучение модели\n",
        "history = cnn_model.fit(\n",
        "    X_ts,\n",
        "    y_main,\n",
        "    epochs=50,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2,\n",
        "    class_weight=compute_class_weight('balanced', classes=np.unique(y_main),\n",
        "                                      y=y_main),\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGigynwqpwed"
      },
      "outputs": [],
      "source": [
        "# Извлечение эмбеддингов\n",
        "_, X_ts_emb = cnn_model.predict(X_ts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3jTcPl9pwed"
      },
      "outputs": [],
      "source": [
        "# 3. Объединение признаков и иерархическая классификация\n",
        "# Объединение FATS и эмбеддингов\n",
        "X_combined = np.concatenate([X_fats, X_ts_emb], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R9nWHWFpwed"
      },
      "outputs": [],
      "source": [
        "# Разделение на тренировочные и тестовые данные\n",
        "X_train, X_test, y_main_train, y_main_test, y_sub_train, y_sub_test = train_test_split(\n",
        "    X_combined, y_main, y_sub, test_size=0.2, stratify=y_main, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xonLzsv7pwed"
      },
      "outputs": [],
      "source": [
        "# 4. Иерархическая модель LightGBM\n",
        "# Уровень 1: Классификация основных классов\n",
        "lgb_main = lgb.LGBMClassifier(\n",
        "    num_leaves=64,\n",
        "    max_depth=-1,\n",
        "    learning_rate=0.05,\n",
        "    n_estimators=300,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "lgb_main.fit(X_train, y_main_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSfjSdq7pwee"
      },
      "outputs": [],
      "source": [
        "# Уровень 2: Классификация подклассов внутри каждого основного класса\n",
        "subclass_models = {}\n",
        "for main_class in np.unique(y_main):\n",
        "    # Фильтрация данных по основному классу\n",
        "    mask = y_main_train == main_class\n",
        "    X_sub_train = X_train[mask]\n",
        "    y_sub_train_filtered = y_sub_train[mask]\n",
        "\n",
        "    # Обучение LightGBM для подклассов\n",
        "    lgb_sub = lgb.LGBMClassifier(\n",
        "        num_leaves=32,\n",
        "        learning_rate=0.1,\n",
        "        n_estimators=200,\n",
        "        class_weight='balanced'\n",
        "    )\n",
        "    lgb_sub.fit(X_sub_train, y_sub_train_filtered)\n",
        "    subclass_models[main_class] = lgb_sub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXYPzv9opwee"
      },
      "outputs": [],
      "source": [
        "main_preds, sub_preds = hierarchical_predict_with_proba(X_test, lgb_main, le_main,\n",
        "                                                        subclass_models, le_sub,\n",
        "                                                        MAIN_THRESHOLD=0.7,\n",
        "                                                        SUB_THRESHOLD=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1tzuANBpwee"
      },
      "outputs": [],
      "source": [
        "# Преобразование меток для оценки\n",
        "main_label, main_prob = main_preds[0]\n",
        "sub_label, sub_prob = sub_preds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0kKWLxdpwee"
      },
      "outputs": [],
      "source": [
        "# Оценка\n",
        "main_report, sub_report = evaluate_hierarchical(\n",
        "    y_main_test,\n",
        "    y_sub_test,\n",
        "    main_preds,\n",
        "    sub_preds,\n",
        "    le_main,\n",
        "    le_sub\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
